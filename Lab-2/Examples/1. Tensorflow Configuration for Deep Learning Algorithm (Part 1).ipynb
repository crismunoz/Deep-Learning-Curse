{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rede Neural Convolutiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "data = input_data.read_data_sets(\"data/MNIST/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuração da Rede Convolutiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 10000\n",
    "batch_size = 128\n",
    "display_step = 10\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "dropout = 0.75 # Dropout, probability to keep units\n",
    "\n",
    "LOG_DIR='logs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definição do Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criação de wrappers por simplicidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Conv2D wrapper, with bias and relu activation\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "# MaxPool2D wrapper\n",
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_net(x_1, weights, biases, keep_prob):\n",
    "\n",
    "    intput = tf.reshape(x_1, shape=[-1, 28, 28, 1], name=\"input\")\n",
    "\n",
    "    with tf.name_scope('conv1'):\n",
    "        conv1 = conv2d(intput, weights['w_c1'], biases['b_c1'])\n",
    "    \n",
    "    with tf.name_scope('pool1'):\n",
    "        pool1 = maxpool2d(conv1, k=2)\n",
    "    \n",
    "    with tf.name_scope('conv2'):\n",
    "        conv2 = conv2d(pool1, weights['w_c2'], biases['b_c2'])\n",
    "    \n",
    "    with tf.name_scope('pool2'):\n",
    "        pool2 = maxpool2d(conv2, k=2)\n",
    "    \n",
    "    with tf.name_scope('local3'):\n",
    "        # Reshape conv2 output to fit fully connected layer input\n",
    "        flat = tf.reshape(pool2, [-1, weights['w_d1'].get_shape().as_list()[0]])\n",
    "        local3 = tf.add(tf.matmul(flat, weights['w_d1']), biases['b_d1'])\n",
    "        local3 = tf.nn.relu(local3)\n",
    "    \n",
    "    with tf.name_scope('dropout'):\n",
    "        dropout4 = tf.nn.dropout(local3, keep_prob)\n",
    "    \n",
    "    with tf.name_scope('logits'):\n",
    "        logits = tf.add(tf.matmul(dropout4, weights['w_out']), biases['b_out'])\n",
    "    \n",
    "    # Summary\n",
    "    tf.summary.histogram('conv1', conv1)\n",
    "    tf.summary.histogram('conv2', conv2)\n",
    "    tf.summary.scalar('dropout_keep_probability', keep_prob)\n",
    "    tf.summary.histogram('logits', logits)\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('weights'):\n",
    "    weights = {\n",
    "        # 5x5 conv, 1 input, 32 outputs\n",
    "        'w_c1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "        # 5x5 conv, 32 inputs, 64 outputs\n",
    "        'w_c2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "        # fully connected, 7*7*64 inputs, 1024 outputs\n",
    "        'w_d1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "        # 1024 inputs, 10 outputs (class prediction)\n",
    "        'w_out': tf.Variable(tf.random_normal([1024, n_classes]))\n",
    "    }\n",
    "\n",
    "with tf.name_scope('biases'):\n",
    "    biases = {\n",
    "        'b_c1': tf.Variable(tf.random_normal([32])),\n",
    "        'b_c2': tf.Variable(tf.random_normal([64])),\n",
    "        'b_d1': tf.Variable(tf.random_normal([1024])),\n",
    "        'b_out': tf.Variable(tf.random_normal([n_classes]))\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construção do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, n_input], name=\"x\")\n",
    "y = tf.placeholder(tf.float32, [None, n_classes],name=\"y\")\n",
    "keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")\n",
    "\n",
    "logits = conv_net(x, weights, biases, keep_prob)\n",
    "\n",
    "cls = tf.argmax(input=logits, axis=1, name=\"classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a função de custo e otimizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('train'):\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medidas de desempenho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('accuracy'):\n",
    "    with tf.name_scope('correct_prediction'):\n",
    "        correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "    with tf.name_scope('accuracy'):\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def variable_summaries(var, key):\n",
    "    with tf.name_scope(str(key) + '_summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean', mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        tf.summary.scalar('stddev', stddev)\n",
    "        tf.summary.scalar('max', tf.reduce_max(var))\n",
    "        tf.summary.scalar('min', tf.reduce_min(var))\n",
    "        tf.summary.histogram('histogram', var)\n",
    "\n",
    "for key, value in weights.items():\n",
    "    variable_summaries(weights[key], key)\n",
    "\n",
    "for key, value in biases.items():\n",
    "    variable_summaries(biases[key], key)\n",
    "    \n",
    "tf.summary.scalar('cross_entropy', cost)  \n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rodamos o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1280, Minibatch Loss= 17612.2, Training Accuracy= 0.34375\n",
      "Iter 2560, Minibatch Loss= 11385.6, Training Accuracy= 0.59375\n",
      "Iter 3840, Minibatch Loss= 6038.98, Training Accuracy= 0.710938\n",
      "Iter 5120, Minibatch Loss= 3274.92, Training Accuracy= 0.765625\n",
      "Iter 6400, Minibatch Loss= 4152.42, Training Accuracy= 0.804688\n",
      "Iter 7680, Minibatch Loss= 1726.96, Training Accuracy= 0.882812\n",
      "Iter 8960, Minibatch Loss= 2443.21, Training Accuracy= 0.851562\n",
      "Otimização Finalizada!\n"
     ]
    }
   ],
   "source": [
    "session = tf.Session()\n",
    "writer = tf.summary.FileWriter(LOG_DIR, session.graph)\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "step = 1\n",
    "\n",
    "while step * batch_size < training_iters:\n",
    "    \n",
    "    x_batch, y_batch = data.train.next_batch(batch_size)\n",
    "    #TODO: Resolver problemas com run_metada\n",
    "    #run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "    #run_metadata = tf.RunMetadata()\n",
    "    \n",
    "    summary , _ = session.run([merged , optimizer], \n",
    "                              feed_dict={x: x_batch, y: y_batch, keep_prob: dropout})#,\n",
    "#                         options = run_options,\n",
    "#                         run_metadata=run_metadata)\n",
    "    \n",
    "#   writer.add_run_metadata(run_metadata, 'step%03d' % step)\n",
    "    writer.add_summary(summary, step)\n",
    "\n",
    "    if step % display_step == 0:\n",
    "        # Calculate batch loss and accuracy\n",
    "        loss, acc = session.run([cost, accuracy], feed_dict={x: x_batch, y: y_batch, keep_prob: 1.})\n",
    "               \n",
    "        print(\"Iter \" + str(step*batch_size) + \\\n",
    "              \", Minibatch Loss= \" + str(loss) + \\\n",
    "              \", Training Accuracy= \" + str(acc))\n",
    "    \n",
    "    step += 1\n",
    "\n",
    "writer.close()\n",
    "\n",
    "print(\"Otimização Finalizada!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feed_dict_test={x: data.test.images,\n",
    "           y: data.test.labels,\n",
    "           keep_prob: 1.}\n",
    "\n",
    "def print_accuracy():\n",
    "    acc = session.run(accuracy , feed_dict=feed_dict_test)\n",
    "    print(\"Acuracia: {0:.1%}\".format(acc) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracia: 86.5%\n"
     ]
    }
   ],
   "source": [
    "print_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testando o modelo com uma imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction=tf.argmax(logits,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADXVJREFUeJzt3XuMXPV5xvHnsVnbxTbETtKtC06MiaEhVBh15aSCRqm4\n1HGoTPIHitsSR0UYpSlqpCgqclWFP6rKrRoQalOqTbBiV4QkUiC4jRsEVlQKoYaFmKshXGyCXWND\nbRWTBF/Wb//YA1rwzpn1nDNzZnm/H2k1M+c9l1dHfnxm5jczP0eEAOQzrekGADSD8ANJEX4gKcIP\nJEX4gaQIP5AU4QeSIvxAUoQfSOqkXh5shmfGLM3u5SGBVN7QL3Q4Dnky61YKv+3lkm6SNF3SNyNi\nXdn6szRbH/VFVQ4JoMTW2DLpdTt+2m97uqSvS/qkpHMkrbJ9Tqf7A9BbVV7zL5P0XES8EBGHJX1H\n0sp62gLQbVXCf5qkl8Y93lUsexvba2yP2B45okMVDgegTl1/tz8ihiNiKCKGBjSz24cDMElVwr9b\n0sJxj08vlgGYAqqE/yFJS2yfYXuGpM9K2lRPWwC6reOhvog4avvPJd2lsaG+9RHxZG2dAeiqSuP8\nEbFZ0uaaegHQQ3y8F0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiB\npAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4\ngaQqzdJre6ekg5JGJR2NiKE6mgLQfZXCX/j9iHi1hv0A6CGe9gNJVQ1/SLrH9sO219TREIDeqPq0\n/8KI2G371yXdbfvpiLh3/ArFfwprJGmWTq54OAB1qXTlj4jdxe0+SXdIWjbBOsMRMRQRQwOaWeVw\nAGrUcfhtz7Y99837ki6V9ERdjQHoripP+wcl3WH7zf18OyJ+VEtXALqu4/BHxAuSzquxFwA9xFAf\nkBThB5Ii/EBShB9IivADSRF+IKk6vtWHNqaf/aHS+q/OmNejTo63/7cGSuvznz5Saf8vXXm0Ze2/\nP/5Ppdte8JMvlNYPH5xRWv/wdTta1kZf/d/SbTPgyg8kRfiBpAg/kBThB5Ii/EBShB9IivADSTHO\nX/BJ5afipa8c9yNFb7nqj8t/xuDC2beV1pfNLB9rn8qOxGjL2oFj5ds+83sbKx178Yw/bVlb8jnG\n+bnyA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBSjPMXysbxJenJa/+5430fGC3/Tvyf7Lyk431L0tad\ni1rW5txfPkXarMv2ltbPPLV8PPz+Z84srZ/+b63/ic25+6nSbZ++8ezS+o4V3yytn3rqL0vr2XHl\nB5Ii/EBShB9IivADSRF+ICnCDyRF+IGk2o7z214v6TJJ+yLi3GLZfEnflbRI0k5JV0TEge612X0f\n2Fze/nlv/FnL2tyft/7OuiSdsr1836NP/ay03s5ibet846+Xl19ps/lZerjjQ3te+XwFq37nwY73\nLUkDtzc3H8JUMJkr/7ckLX/HsuskbYmIJZK2FI8BTCFtwx8R90ra/47FKyVtKO5vkHR5zX0B6LJO\nX/MPRsSe4v7LkgZr6gdAj1R+wy8iQlK0qtteY3vE9sgRHap6OAA16TT8e20vkKTidl+rFSNiOCKG\nImJoQDM7PByAunUa/k2SVhf3V0u6s552APRK2/Dbvk3SA5LOtr3L9lWS1km6xPazki4uHgOYQtqO\n80fEqhali2rupVHHHt1eWv+NRzvfd/mnABJ773tKy387+OPS+p6jr5fWT33+VyfcUiZ8wg9IivAD\nSRF+ICnCDyRF+IGkCD+QFD/dja6aNnduy9qBf6x27Vn5118prc+774FK+3+348oPJEX4gaQIP5AU\n4QeSIvxAUoQfSIrwA0kxzo+u+r9PfaRl7YHz/qXSvt+/5eel9aOV9v7ux5UfSIrwA0kRfiApwg8k\nRfiBpAg/kBThB5JinB9d9cZ73PG2H7r1C6X1M/+n2hTe2XHlB5Ii/EBShB9IivADSRF+ICnCDyRF\n+IGk2o7z214v6TJJ+yLi3GLZ9ZKulvRKsdraiNjcrSbRv6bNmlVaX37N/S1r2w4dKt327Bt2lNaP\nHmPy8yomc+X/lqTlEyy/MSKWFn8EH5hi2oY/Iu6VtL8HvQDooSqv+a+1/Zjt9bbn1dYRgJ7oNPw3\nS1osaamkPZK+1mpF22tsj9geOaLy13gAeqej8EfE3ogYjYhjkr4haVnJusMRMRQRQwOa2WmfAGrW\nUfhtLxj38NOSnqinHQC9MpmhvtskfULS+2zvkvRVSZ+wvVRSSNop6Zou9gigC9qGPyJWTbD4li70\ngilox9rzS+v/MXhzy9rvPvpHpduesuf5jnrC5PAJPyApwg8kRfiBpAg/kBThB5Ii/EBS/HQ3yk2b\nXlq+dMVIaX00jrWszVl3SkctoR5c+YGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcb5Uer5v2v5I02S\npLt+s/VXdiXpM8/9QcvatP/8aUc9oR5c+YGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcb5UWrWma9V\n2v6nTy9qWTvrrRne0QSu/EBShB9IivADSRF+ICnCDyRF+IGkCD+QVNtxftsLJW2UNCgpJA1HxE22\n50v6rqRFknZKuiIiDnSvVXSDB2aU1v/mt+8srf/y2OHS+sIf+oR7Qm9M5sp/VNKXI+IcSR+T9EXb\n50i6TtKWiFgiaUvxGMAU0Tb8EbEnIh4p7h+UtF3SaZJWStpQrLZB0uXdahJA/U7oNb/tRZLOl7RV\n0mBE7ClKL2vsZQGAKWLS4bc9R9L3JX0pIt72ge+ICI29HzDRdmtsj9geOaJDlZoFUJ9Jhd/2gMaC\nf2tE3F4s3mt7QVFfIGnfRNtGxHBEDEXE0IBm1tEzgBq0Db9tS7pF0vaIuGFcaZOk1cX91ZLK3xYG\n0Fcm85XeCyRdKelx29uKZWslrZP0PdtXSXpR0hXdaRHd9Is/PL+0fvnsB0vrn3vx4tL6r91Zvj2a\n0zb8EXGfpFaDtRfV2w6AXuETfkBShB9IivADSRF+ICnCDyRF+IGk+Onu5C7+6n9V2n7kh+eW1hfq\nJ5X2j+7hyg8kRfiBpAg/kBThB5Ii/EBShB9IivADSTHO/y437eSTS+vzT6r2a+sfuOtgaX3C33ZD\nX+DKDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJMc7/Lnf4Yx8urV87r9r37fd/ZE5pfd5DlXaPLuLK\nDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJtR3nt71Q0kZJgxr7evZwRNxk+3pJV0t6pVh1bURs7laj\n6MyOz1f7Rv0Z/351af2sjQ9W2j+aM5kP+RyV9OWIeMT2XEkP2767qN0YEf/QvfYAdEvb8EfEHkl7\nivsHbW+XdFq3GwPQXSf0mt/2IknnS9paLLrW9mO219ue12KbNbZHbI8c0aFKzQKoz6TDb3uOpO9L\n+lJEvCbpZkmLJS3V2DODr020XUQMR8RQRAwNaGYNLQOow6TCb3tAY8G/NSJul6SI2BsRoxFxTNI3\nJC3rXpsA6tY2/LYt6RZJ2yPihnHLF4xb7dOSnqi/PQDdMpl3+y+QdKWkx21vK5atlbTK9lKNDf/t\nlHRNVzpEJTNfmFVaH41jpfUP/qDNAY6NnmBH6BeTebf/PkmeoMSYPjCF8Qk/ICnCDyRF+IGkCD+Q\nFOEHkiL8QFKO6N0kyqd4fnzUF/XseEA2W2OLXov9Ew3NH4crP5AU4QeSIvxAUoQfSIrwA0kRfiAp\nwg8k1dNxftuvSHpx3KL3SXq1Zw2cmH7trV/7kuitU3X29sGIeP9kVuxp+I87uD0SEUONNVCiX3vr\n174keutUU73xtB9IivADSTUd/uGGj1+mX3vr174keutUI701+pofQHOavvIDaEgj4be93PYztp+z\nfV0TPbRie6ftx21vsz3ScC/rbe+z/cS4ZfNt32372eJ2wmnSGurtetu7i3O3zfaKhnpbaPvHtp+y\n/aTtvyiWN3ruSvpq5Lz1/Gm/7emSfibpEkm7JD0kaVVEPNXTRlqwvVPSUEQ0PiZs++OSXpe0MSLO\nLZb9vaT9EbGu+I9zXkT8ZZ/0dr2k15ueubmYUGbB+JmlJV0u6fNq8NyV9HWFGjhvTVz5l0l6LiJe\niIjDkr4jaWUDffS9iLhX0v53LF4paUNxf4PG/vH0XIve+kJE7ImIR4r7ByW9ObN0o+eupK9GNBH+\n0yS9NO7xLvXXlN8h6R7bD9te03QzExgspk2XpJclDTbZzATaztzcS++YWbpvzl0nM17XjTf8jndh\nRCyV9ElJXyye3valGHvN1k/DNZOaublXJphZ+i1NnrtOZ7yuWxPh3y1p4bjHpxfL+kJE7C5u90m6\nQ/03+/DeNydJLW73NdzPW/pp5uaJZpZWH5y7fprxuonwPyRpie0zbM+Q9FlJmxro4zi2ZxdvxMj2\nbEmXqv9mH94kaXVxf7WkOxvs5W36ZebmVjNLq+Fz13czXkdEz/8krdDYO/7PS/qrJnpo0ddiSY8W\nf0823Zuk2zT2NPCIxt4buUrSeyVtkfSspHskze+j3v5V0uOSHtNY0BY01NuFGntK/5ikbcXfiqbP\nXUlfjZw3PuEHJMUbfkBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkvp/bw4NNdBK5x4AAAAASUVO\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f700414eb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "n=100\n",
    "img_input = data.train.images[n:(n+1)]\n",
    "img=np.reshape(img_input, (28,28))\n",
    "plt.imshow(img)\n",
    "print(session.run(prediction, feed_dict={x: img_input , keep_prob: 1}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
