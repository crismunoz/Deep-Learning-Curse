{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import gym\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "import collections\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next_batch(experience, model, num_actions, gamma, state_size, batch_size):\n",
    "    \n",
    "    batch_indices = np.random.randint(low=0, high=len(experience), size=batch_size)\n",
    "    #batch = [experience[i] for i in batch_indices]\n",
    "    batch = random.sample(experience, batch_size)\n",
    "    X = np.zeros((batch_size, state_size))\n",
    "    Y = np.zeros((batch_size, num_actions))\n",
    "    for i in range(len(batch)):\n",
    "        s_t, a_t, r_t, s_tp1, done = batch[i]\n",
    "        X[i] = s_t\n",
    "        Y[i] = model.predict(s_t)[0]\n",
    "        Q_sa = np.max(model.predict(s_tp1)[0])\n",
    "        if done:\n",
    "            Y[i, a_t] = r_t\n",
    "        else:\n",
    "            Y[i, a_t] = r_t + gamma * Q_sa\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"data\"\n",
    "GAMMA = 0.95 # decay rate of past observations\n",
    "INITIAL_EPSILON = 0.1 # starting value of epsilon\n",
    "FINAL_EPSILON = 0.001 # final value of epsilon\n",
    "MEMORY_SIZE = 2000 # number of previous transitions to remember\n",
    "NUM_EPOCHS_OBSERVE = 100\n",
    "NUM_EPOCHS_TRAIN = 150\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = NUM_EPOCHS_OBSERVE + NUM_EPOCHS_TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-13 12:03:36,231] Making new env: CartPole-v0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "STATE_SIZE = env.observation_space.shape[0]\n",
    "NUM_ACTIONS = env.action_space.n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(24, input_dim=STATE_SIZE, activation='relu'))\n",
    "model.add(Dense(24, activation='relu'))\n",
    "model.add(Dense(NUM_ACTIONS, activation='linear'))\n",
    "model.compile(loss='mse', optimizer=Adam(lr=0.001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0001/250 | Loss 0.00000 | score 12.00000 | reward 2.000000\n",
      "Epoch 0002/250 | Loss 0.00000 | score 23.00000 | reward 13.000000\n",
      "Epoch 0003/250 | Loss 0.00000 | score 19.00000 | reward 9.000000\n",
      "Epoch 0004/250 | Loss 0.00000 | score 17.00000 | reward 7.000000\n",
      "Epoch 0005/250 | Loss 0.00000 | score 64.00000 | reward 54.000000\n",
      "Epoch 0006/250 | Loss 0.00000 | score 13.00000 | reward 3.000000\n",
      "Epoch 0007/250 | Loss 0.00000 | score 41.00000 | reward 31.000000\n",
      "Epoch 0008/250 | Loss 0.00000 | score 16.00000 | reward 6.000000\n",
      "Epoch 0009/250 | Loss 0.00000 | score 36.00000 | reward 26.000000\n",
      "Epoch 0010/250 | Loss 0.00000 | score 23.00000 | reward 13.000000\n",
      "Epoch 0011/250 | Loss 0.00000 | score 18.00000 | reward 8.000000\n",
      "Epoch 0012/250 | Loss 0.00000 | score 8.00000 | reward -2.000000\n",
      "Epoch 0013/250 | Loss 0.00000 | score 33.00000 | reward 23.000000\n",
      "Epoch 0014/250 | Loss 0.00000 | score 10.00000 | reward 0.000000\n",
      "Epoch 0015/250 | Loss 0.00000 | score 13.00000 | reward 3.000000\n",
      "Epoch 0016/250 | Loss 0.00000 | score 11.00000 | reward 1.000000\n",
      "Epoch 0017/250 | Loss 0.00000 | score 38.00000 | reward 28.000000\n",
      "Epoch 0018/250 | Loss 0.00000 | score 27.00000 | reward 17.000000\n",
      "Epoch 0019/250 | Loss 0.00000 | score 11.00000 | reward 1.000000\n",
      "Epoch 0020/250 | Loss 0.00000 | score 18.00000 | reward 8.000000\n",
      "Epoch 0021/250 | Loss 0.00000 | score 30.00000 | reward 20.000000\n",
      "Epoch 0022/250 | Loss 0.00000 | score 16.00000 | reward 6.000000\n",
      "Epoch 0023/250 | Loss 0.00000 | score 13.00000 | reward 3.000000\n",
      "Epoch 0024/250 | Loss 0.00000 | score 17.00000 | reward 7.000000\n",
      "Epoch 0025/250 | Loss 0.00000 | score 11.00000 | reward 1.000000\n",
      "Epoch 0026/250 | Loss 0.00000 | score 39.00000 | reward 29.000000\n",
      "Epoch 0027/250 | Loss 0.00000 | score 70.00000 | reward 60.000000\n",
      "Epoch 0028/250 | Loss 0.00000 | score 17.00000 | reward 7.000000\n",
      "Epoch 0029/250 | Loss 0.00000 | score 18.00000 | reward 8.000000\n",
      "Epoch 0030/250 | Loss 0.00000 | score 34.00000 | reward 24.000000\n",
      "Epoch 0031/250 | Loss 0.00000 | score 22.00000 | reward 12.000000\n",
      "Epoch 0032/250 | Loss 0.00000 | score 17.00000 | reward 7.000000\n",
      "Epoch 0033/250 | Loss 0.00000 | score 28.00000 | reward 18.000000\n",
      "Epoch 0034/250 | Loss 0.00000 | score 17.00000 | reward 7.000000\n",
      "Epoch 0035/250 | Loss 0.00000 | score 17.00000 | reward 7.000000\n",
      "Epoch 0036/250 | Loss 0.00000 | score 8.00000 | reward -2.000000\n",
      "Epoch 0037/250 | Loss 0.00000 | score 14.00000 | reward 4.000000\n",
      "Epoch 0038/250 | Loss 0.00000 | score 32.00000 | reward 22.000000\n",
      "Epoch 0039/250 | Loss 0.00000 | score 9.00000 | reward -1.000000\n",
      "Epoch 0040/250 | Loss 0.00000 | score 16.00000 | reward 6.000000\n",
      "Epoch 0041/250 | Loss 0.00000 | score 33.00000 | reward 23.000000\n",
      "Epoch 0042/250 | Loss 0.00000 | score 15.00000 | reward 5.000000\n",
      "Epoch 0043/250 | Loss 0.00000 | score 15.00000 | reward 5.000000\n",
      "Epoch 0044/250 | Loss 0.00000 | score 24.00000 | reward 14.000000\n",
      "Epoch 0045/250 | Loss 0.00000 | score 22.00000 | reward 12.000000\n",
      "Epoch 0046/250 | Loss 0.00000 | score 45.00000 | reward 35.000000\n",
      "Epoch 0047/250 | Loss 0.00000 | score 19.00000 | reward 9.000000\n",
      "Epoch 0048/250 | Loss 0.00000 | score 43.00000 | reward 33.000000\n",
      "Epoch 0049/250 | Loss 0.00000 | score 17.00000 | reward 7.000000\n",
      "Epoch 0050/250 | Loss 0.00000 | score 21.00000 | reward 11.000000\n",
      "Epoch 0051/250 | Loss 0.00000 | score 37.00000 | reward 27.000000\n",
      "Epoch 0052/250 | Loss 0.00000 | score 12.00000 | reward 2.000000\n",
      "Epoch 0053/250 | Loss 0.00000 | score 22.00000 | reward 12.000000\n",
      "Epoch 0054/250 | Loss 0.00000 | score 20.00000 | reward 10.000000\n",
      "Epoch 0055/250 | Loss 0.00000 | score 10.00000 | reward 0.000000\n",
      "Epoch 0056/250 | Loss 0.00000 | score 14.00000 | reward 4.000000\n",
      "Epoch 0057/250 | Loss 0.00000 | score 26.00000 | reward 16.000000\n",
      "Epoch 0058/250 | Loss 0.00000 | score 18.00000 | reward 8.000000\n",
      "Epoch 0059/250 | Loss 0.00000 | score 29.00000 | reward 19.000000\n",
      "Epoch 0060/250 | Loss 0.00000 | score 12.00000 | reward 2.000000\n",
      "Epoch 0061/250 | Loss 0.00000 | score 15.00000 | reward 5.000000\n",
      "Epoch 0062/250 | Loss 0.00000 | score 8.00000 | reward -2.000000\n",
      "Epoch 0063/250 | Loss 0.00000 | score 13.00000 | reward 3.000000\n",
      "Epoch 0064/250 | Loss 0.00000 | score 11.00000 | reward 1.000000\n",
      "Epoch 0065/250 | Loss 0.00000 | score 28.00000 | reward 18.000000\n",
      "Epoch 0066/250 | Loss 0.00000 | score 15.00000 | reward 5.000000\n",
      "Epoch 0067/250 | Loss 0.00000 | score 21.00000 | reward 11.000000\n",
      "Epoch 0068/250 | Loss 0.00000 | score 8.00000 | reward -2.000000\n",
      "Epoch 0069/250 | Loss 0.00000 | score 8.00000 | reward -2.000000\n",
      "Epoch 0070/250 | Loss 0.00000 | score 23.00000 | reward 13.000000\n",
      "Epoch 0071/250 | Loss 0.00000 | score 16.00000 | reward 6.000000\n",
      "Epoch 0072/250 | Loss 0.00000 | score 8.00000 | reward -2.000000\n",
      "Epoch 0073/250 | Loss 0.00000 | score 15.00000 | reward 5.000000\n",
      "Epoch 0074/250 | Loss 0.00000 | score 38.00000 | reward 28.000000\n",
      "Epoch 0075/250 | Loss 0.00000 | score 18.00000 | reward 8.000000\n",
      "Epoch 0076/250 | Loss 0.00000 | score 12.00000 | reward 2.000000\n",
      "Epoch 0077/250 | Loss 0.00000 | score 20.00000 | reward 10.000000\n",
      "Epoch 0078/250 | Loss 0.00000 | score 66.00000 | reward 56.000000\n",
      "Epoch 0079/250 | Loss 0.00000 | score 24.00000 | reward 14.000000\n",
      "Epoch 0080/250 | Loss 0.00000 | score 11.00000 | reward 1.000000\n",
      "Epoch 0081/250 | Loss 0.00000 | score 15.00000 | reward 5.000000\n",
      "Epoch 0082/250 | Loss 0.00000 | score 11.00000 | reward 1.000000\n",
      "Epoch 0083/250 | Loss 0.00000 | score 28.00000 | reward 18.000000\n",
      "Epoch 0084/250 | Loss 0.00000 | score 41.00000 | reward 31.000000\n",
      "Epoch 0085/250 | Loss 0.00000 | score 15.00000 | reward 5.000000\n",
      "Epoch 0086/250 | Loss 0.00000 | score 13.00000 | reward 3.000000\n",
      "Epoch 0087/250 | Loss 0.00000 | score 22.00000 | reward 12.000000\n",
      "Epoch 0088/250 | Loss 0.00000 | score 19.00000 | reward 9.000000\n",
      "Epoch 0089/250 | Loss 0.00000 | score 20.00000 | reward 10.000000\n",
      "Epoch 0090/250 | Loss 0.00000 | score 29.00000 | reward 19.000000\n",
      "Epoch 0091/250 | Loss 0.00000 | score 14.00000 | reward 4.000000\n",
      "Epoch 0092/250 | Loss 0.00000 | score 13.00000 | reward 3.000000\n",
      "Epoch 0093/250 | Loss 0.00000 | score 16.00000 | reward 6.000000\n",
      "Epoch 0094/250 | Loss 0.00000 | score 12.00000 | reward 2.000000\n",
      "Epoch 0095/250 | Loss 0.00000 | score 17.00000 | reward 7.000000\n",
      "Epoch 0096/250 | Loss 0.00000 | score 17.00000 | reward 7.000000\n",
      "Epoch 0097/250 | Loss 0.00000 | score 14.00000 | reward 4.000000\n",
      "Epoch 0098/250 | Loss 0.00000 | score 9.00000 | reward -1.000000\n",
      "Epoch 0099/250 | Loss 0.00000 | score 39.00000 | reward 29.000000\n",
      "Epoch 0100/250 | Loss 0.00000 | score 18.00000 | reward 8.000000\n",
      "Epoch 0101/250 | Loss 0.00000 | score 14.00000 | reward 4.000000\n",
      "Epoch 0102/250 | Loss 976.48232 | score 194.00000 | reward 195.000000\n",
      "Epoch 0103/250 | Loss 957.53658 | score 194.00000 | reward 195.000000\n",
      "Epoch 0104/250 | Loss 675.93239 | score 194.00000 | reward 195.000000\n",
      "Epoch 0105/250 | Loss 464.78115 | score 194.00000 | reward 195.000000\n",
      "Epoch 0106/250 | Loss 374.56861 | score 194.00000 | reward 195.000000\n",
      "Epoch 0107/250 | Loss 233.06840 | score 194.00000 | reward 195.000000\n",
      "Epoch 0108/250 | Loss 156.90390 | score 194.00000 | reward 195.000000\n",
      "Epoch 0109/250 | Loss 117.41903 | score 194.00000 | reward 195.000000\n",
      "Epoch 0110/250 | Loss 65.43074 | score 194.00000 | reward 195.000000\n",
      "Epoch 0111/250 | Loss 44.96530 | score 194.00000 | reward 195.000000\n",
      "Epoch 0112/250 | Loss 9.66720 | score 194.00000 | reward 195.000000\n",
      "Epoch 0113/250 | Loss 5.06624 | score 194.00000 | reward 195.000000\n",
      "Epoch 0114/250 | Loss 3.73189 | score 194.00000 | reward 195.000000\n",
      "Epoch 0115/250 | Loss 2.89724 | score 174.00000 | reward 164.000000\n",
      "Epoch 0116/250 | Loss 33.24643 | score 194.00000 | reward 195.000000\n",
      "Epoch 0117/250 | Loss 16.12737 | score 194.00000 | reward 195.000000\n",
      "Epoch 0118/250 | Loss 10.70675 | score 194.00000 | reward 195.000000\n",
      "Epoch 0119/250 | Loss 5.46010 | score 194.00000 | reward 195.000000\n",
      "Epoch 0120/250 | Loss 12.84742 | score 194.00000 | reward 195.000000\n",
      "Epoch 0121/250 | Loss 31.66465 | score 194.00000 | reward 195.000000\n",
      "Epoch 0122/250 | Loss 7.68849 | score 194.00000 | reward 195.000000\n",
      "Epoch 0123/250 | Loss 18.33120 | score 194.00000 | reward 195.000000\n",
      "Epoch 0124/250 | Loss 19.51191 | score 176.00000 | reward 166.000000\n",
      "Epoch 0125/250 | Loss 42.08613 | score 193.00000 | reward 183.000000\n",
      "Epoch 0126/250 | Loss 36.57941 | score 194.00000 | reward 195.000000\n",
      "Epoch 0127/250 | Loss 28.69774 | score 191.00000 | reward 181.000000\n",
      "Epoch 0128/250 | Loss 44.43933 | score 194.00000 | reward 184.000000\n",
      "Epoch 0129/250 | Loss 43.70956 | score 184.00000 | reward 174.000000\n",
      "Epoch 0130/250 | Loss 43.46488 | score 181.00000 | reward 171.000000\n",
      "Epoch 0131/250 | Loss 54.20344 | score 173.00000 | reward 163.000000\n",
      "Epoch 0132/250 | Loss 43.98653 | score 157.00000 | reward 147.000000\n",
      "Epoch 0133/250 | Loss 68.70885 | score 160.00000 | reward 150.000000\n",
      "Epoch 0134/250 | Loss 75.73396 | score 183.00000 | reward 173.000000\n",
      "Epoch 0135/250 | Loss 43.47405 | score 170.00000 | reward 160.000000\n",
      "Epoch 0136/250 | Loss 33.40689 | score 165.00000 | reward 155.000000\n",
      "Epoch 0137/250 | Loss 32.45808 | score 162.00000 | reward 152.000000\n",
      "Epoch 0138/250 | Loss 28.79216 | score 165.00000 | reward 155.000000\n",
      "Epoch 0139/250 | Loss 20.00423 | score 155.00000 | reward 145.000000\n",
      "Epoch 0140/250 | Loss 20.24559 | score 168.00000 | reward 158.000000\n",
      "Epoch 0141/250 | Loss 20.32955 | score 172.00000 | reward 162.000000\n",
      "Epoch 0142/250 | Loss 15.49660 | score 176.00000 | reward 166.000000\n",
      "Epoch 0143/250 | Loss 11.88159 | score 181.00000 | reward 171.000000\n",
      "Epoch 0144/250 | Loss 9.07839 | score 172.00000 | reward 162.000000\n",
      "Epoch 0145/250 | Loss 6.17612 | score 188.00000 | reward 178.000000\n",
      "Epoch 0146/250 | Loss 7.02911 | score 175.00000 | reward 165.000000\n",
      "Epoch 0147/250 | Loss 5.49438 | score 193.00000 | reward 183.000000\n",
      "Epoch 0148/250 | Loss 4.81072 | score 192.00000 | reward 182.000000\n",
      "Epoch 0149/250 | Loss 3.12530 | score 193.00000 | reward 183.000000\n",
      "Epoch 0150/250 | Loss 2.72973 | score 181.00000 | reward 171.000000\n",
      "Epoch 0151/250 | Loss 3.42005 | score 187.00000 | reward 177.000000\n",
      "Epoch 0152/250 | Loss 7.35806 | score 174.00000 | reward 164.000000\n",
      "Epoch 0153/250 | Loss 7.06368 | score 194.00000 | reward 195.000000\n",
      "Epoch 0154/250 | Loss 6.19437 | score 194.00000 | reward 195.000000\n",
      "Epoch 0155/250 | Loss 10.34884 | score 194.00000 | reward 195.000000\n",
      "Epoch 0156/250 | Loss 5.03551 | score 194.00000 | reward 195.000000\n",
      "Epoch 0157/250 | Loss 3.00843 | score 194.00000 | reward 195.000000\n",
      "Epoch 0158/250 | Loss 4.25899 | score 193.00000 | reward 183.000000\n",
      "Epoch 0159/250 | Loss 15.00080 | score 181.00000 | reward 171.000000\n",
      "Epoch 0160/250 | Loss 17.79875 | score 46.00000 | reward 36.000000\n",
      "Epoch 0161/250 | Loss 0.81481 | score 12.00000 | reward 2.000000\n",
      "Epoch 0162/250 | Loss 88.75779 | score 44.00000 | reward 34.000000\n",
      "Epoch 0163/250 | Loss 62.51664 | score 17.00000 | reward 7.000000\n",
      "Epoch 0164/250 | Loss 114.97203 | score 136.00000 | reward 126.000000\n",
      "Epoch 0165/250 | Loss 115.60001 | score 186.00000 | reward 176.000000\n",
      "Epoch 0166/250 | Loss 72.01080 | score 194.00000 | reward 195.000000\n",
      "Epoch 0167/250 | Loss 99.27944 | score 194.00000 | reward 195.000000\n",
      "Epoch 0168/250 | Loss 126.76340 | score 194.00000 | reward 195.000000\n",
      "Epoch 0169/250 | Loss 42.77354 | score 194.00000 | reward 195.000000\n",
      "Epoch 0170/250 | Loss 93.38191 | score 194.00000 | reward 195.000000\n",
      "Epoch 0171/250 | Loss 111.86950 | score 194.00000 | reward 195.000000\n",
      "Epoch 0172/250 | Loss 95.45680 | score 194.00000 | reward 195.000000\n",
      "Epoch 0173/250 | Loss 51.44323 | score 194.00000 | reward 195.000000\n",
      "Epoch 0174/250 | Loss 16.73122 | score 194.00000 | reward 195.000000\n",
      "Epoch 0175/250 | Loss 3.87993 | score 194.00000 | reward 195.000000\n",
      "Epoch 0176/250 | Loss 1.10248 | score 194.00000 | reward 195.000000\n",
      "Epoch 0177/250 | Loss 0.69702 | score 194.00000 | reward 195.000000\n",
      "Epoch 0178/250 | Loss 0.51574 | score 194.00000 | reward 195.000000\n",
      "Epoch 0179/250 | Loss 0.58260 | score 194.00000 | reward 195.000000\n",
      "Epoch 0180/250 | Loss 0.49193 | score 194.00000 | reward 195.000000\n",
      "Epoch 0181/250 | Loss 0.42693 | score 194.00000 | reward 195.000000\n",
      "Epoch 0182/250 | Loss 0.25273 | score 194.00000 | reward 195.000000\n",
      "Epoch 0183/250 | Loss 0.25884 | score 194.00000 | reward 195.000000\n",
      "Epoch 0184/250 | Loss 0.19232 | score 194.00000 | reward 195.000000\n",
      "Epoch 0185/250 | Loss 0.15668 | score 194.00000 | reward 195.000000\n",
      "Epoch 0186/250 | Loss 0.19787 | score 194.00000 | reward 195.000000\n",
      "Epoch 0187/250 | Loss 0.18042 | score 194.00000 | reward 195.000000\n",
      "Epoch 0188/250 | Loss 0.16540 | score 194.00000 | reward 195.000000\n",
      "Epoch 0189/250 | Loss 0.14660 | score 194.00000 | reward 195.000000\n",
      "Epoch 0190/250 | Loss 0.14048 | score 194.00000 | reward 195.000000\n",
      "Epoch 0191/250 | Loss 0.13929 | score 194.00000 | reward 195.000000\n",
      "Epoch 0192/250 | Loss 0.12739 | score 194.00000 | reward 195.000000\n",
      "Epoch 0193/250 | Loss 0.08337 | score 194.00000 | reward 195.000000\n",
      "Epoch 0194/250 | Loss 0.06732 | score 194.00000 | reward 195.000000\n",
      "Epoch 0195/250 | Loss 0.06493 | score 194.00000 | reward 195.000000\n",
      "Epoch 0196/250 | Loss 0.05665 | score 194.00000 | reward 195.000000\n",
      "Epoch 0197/250 | Loss 0.04638 | score 194.00000 | reward 195.000000\n",
      "Epoch 0198/250 | Loss 0.16024 | score 194.00000 | reward 195.000000\n",
      "Epoch 0199/250 | Loss 0.31742 | score 194.00000 | reward 195.000000\n",
      "Epoch 0200/250 | Loss 0.32443 | score 194.00000 | reward 195.000000\n",
      "Epoch 0201/250 | Loss 0.24131 | score 194.00000 | reward 195.000000\n",
      "Epoch 0202/250 | Loss 0.16331 | score 194.00000 | reward 195.000000\n",
      "Epoch 0203/250 | Loss 0.24689 | score 194.00000 | reward 195.000000\n",
      "Epoch 0204/250 | Loss 0.23462 | score 194.00000 | reward 195.000000\n",
      "Epoch 0205/250 | Loss 0.21964 | score 194.00000 | reward 195.000000\n",
      "Epoch 0206/250 | Loss 0.19266 | score 194.00000 | reward 195.000000\n",
      "Epoch 0207/250 | Loss 0.16622 | score 194.00000 | reward 195.000000\n",
      "Epoch 0208/250 | Loss 0.12169 | score 194.00000 | reward 195.000000\n",
      "Epoch 0209/250 | Loss 0.21132 | score 194.00000 | reward 195.000000\n",
      "Epoch 0210/250 | Loss 0.19703 | score 194.00000 | reward 195.000000\n",
      "Epoch 0211/250 | Loss 0.13468 | score 194.00000 | reward 195.000000\n",
      "Epoch 0212/250 | Loss 0.10243 | score 194.00000 | reward 195.000000\n",
      "Epoch 0213/250 | Loss 0.23773 | score 194.00000 | reward 195.000000\n",
      "Epoch 0214/250 | Loss 2.28321 | score 110.00000 | reward 100.000000\n",
      "Epoch 0215/250 | Loss 14.50914 | score 50.00000 | reward 40.000000\n",
      "Epoch 0216/250 | Loss 32.83931 | score 60.00000 | reward 50.000000\n",
      "Epoch 0217/250 | Loss 100.66821 | score 187.00000 | reward 177.000000\n",
      "Epoch 0218/250 | Loss 64.46541 | score 194.00000 | reward 195.000000\n",
      "Epoch 0219/250 | Loss 23.76463 | score 194.00000 | reward 195.000000\n",
      "Epoch 0220/250 | Loss 64.00100 | score 194.00000 | reward 195.000000\n",
      "Epoch 0221/250 | Loss 44.45204 | score 194.00000 | reward 195.000000\n",
      "Epoch 0222/250 | Loss 82.98749 | score 194.00000 | reward 195.000000\n",
      "Epoch 0223/250 | Loss 35.03531 | score 194.00000 | reward 195.000000\n",
      "Epoch 0224/250 | Loss 29.62677 | score 194.00000 | reward 195.000000\n",
      "Epoch 0225/250 | Loss 48.16350 | score 194.00000 | reward 195.000000\n",
      "Epoch 0226/250 | Loss 29.93634 | score 194.00000 | reward 195.000000\n",
      "Epoch 0227/250 | Loss 5.19333 | score 194.00000 | reward 195.000000\n",
      "Epoch 0228/250 | Loss 1.22245 | score 194.00000 | reward 195.000000\n",
      "Epoch 0229/250 | Loss 0.88373 | score 194.00000 | reward 195.000000\n",
      "Epoch 0230/250 | Loss 0.75019 | score 194.00000 | reward 195.000000\n",
      "Epoch 0231/250 | Loss 0.68218 | score 194.00000 | reward 195.000000\n",
      "Epoch 0232/250 | Loss 0.81276 | score 194.00000 | reward 195.000000\n",
      "Epoch 0233/250 | Loss 0.77897 | score 194.00000 | reward 195.000000\n",
      "Epoch 0234/250 | Loss 0.74768 | score 194.00000 | reward 195.000000\n",
      "Epoch 0235/250 | Loss 0.47564 | score 194.00000 | reward 195.000000\n",
      "Epoch 0236/250 | Loss 0.58068 | score 194.00000 | reward 195.000000\n",
      "Epoch 0237/250 | Loss 0.35535 | score 194.00000 | reward 195.000000\n",
      "Epoch 0238/250 | Loss 0.44100 | score 194.00000 | reward 195.000000\n",
      "Epoch 0239/250 | Loss 0.42452 | score 194.00000 | reward 195.000000\n",
      "Epoch 0240/250 | Loss 0.29919 | score 194.00000 | reward 195.000000\n",
      "Epoch 0241/250 | Loss 0.24800 | score 194.00000 | reward 195.000000\n",
      "Epoch 0242/250 | Loss 0.26820 | score 194.00000 | reward 195.000000\n",
      "Epoch 0243/250 | Loss 0.28295 | score 194.00000 | reward 195.000000\n",
      "Epoch 0244/250 | Loss 0.28910 | score 194.00000 | reward 195.000000\n",
      "Epoch 0245/250 | Loss 0.27983 | score 194.00000 | reward 195.000000\n",
      "Epoch 0246/250 | Loss 0.23260 | score 194.00000 | reward 195.000000\n",
      "Epoch 0247/250 | Loss 0.21524 | score 194.00000 | reward 195.000000\n",
      "Epoch 0248/250 | Loss 0.20771 | score 194.00000 | reward 195.000000\n",
      "Epoch 0249/250 | Loss 0.17785 | score 194.00000 | reward 195.000000\n",
      "Epoch 0250/250 | Loss 0.16330 | score 194.00000 | reward 195.000000\n",
      "--- Tempo total: 381 seconds ---\n"
     ]
    }
   ],
   "source": [
    "experience = collections.deque(maxlen=MEMORY_SIZE)\n",
    "fout = open(os.path.join(DATA_DIR, \"rl-network-results.tsv\"), \"w\")\n",
    "epsilon = INITIAL_EPSILON\n",
    "done = False\n",
    "\n",
    "start_time = time.time()\n",
    "for e in range(NUM_EPOCHS):\n",
    "    loss = 0.0\n",
    "    s_t = env.reset()\n",
    "    s_t = np.reshape(s_t, [1, STATE_SIZE])\n",
    "    reward = 0\n",
    "    for step in range(195):\n",
    "        s_tm1 = s_t\n",
    "        # next action\n",
    "        if e <= NUM_EPOCHS_OBSERVE:\n",
    "            a_t = np.random.randint(low=0, high=NUM_ACTIONS, size=1)[0]\n",
    "        else:\n",
    "            if np.random.rand() <= epsilon:\n",
    "                a_t = np.random.randint(low=0, high=NUM_ACTIONS, size=1)[0]\n",
    "            else:\n",
    "                q = model.predict(s_t)[0]\n",
    "                a_t = np.argmax(q)\n",
    "                \n",
    "        # apply action, get reward\n",
    "        s_t, r_t, done, _ = env.step(a_t)\n",
    "        r_t = r_t if not done else -10\n",
    "        s_t = np.reshape(s_t, [1, STATE_SIZE])\n",
    "        reward +=r_t \n",
    "        # store experience\n",
    "        experience.append((s_tm1, a_t, r_t, s_t, done))\n",
    "        \n",
    "        if e > NUM_EPOCHS_OBSERVE:\n",
    "            # finished observing, now start training\n",
    "            # get next batch\n",
    "            X, Y = get_next_batch(experience, model, NUM_ACTIONS, \n",
    "                                  GAMMA, STATE_SIZE, BATCH_SIZE)\n",
    "            loss += model.train_on_batch(X, Y)\n",
    "        \n",
    "        if done:\n",
    "            break;\n",
    "            \n",
    "    print(\"Epoch {:04d}/{:d} | Loss {:.5f} | score {:.5f} | reward {:5f}\"\n",
    "                  .format(e + 1, NUM_EPOCHS, loss, step, reward))            \n",
    "    # reduce epsilon gradually\n",
    "    if epsilon > FINAL_EPSILON:\n",
    "        epsilon -= (INITIAL_EPSILON - FINAL_EPSILON) / NUM_EPOCHS\n",
    "        \n",
    "    \n",
    "    fout.write(\"{:04d}\\t{:.5f}\\n\".format(e + 1, loss))\n",
    "\n",
    "    if e % 100 == 0:\n",
    "        model.save(os.path.join(DATA_DIR, \"rl-network.h5\"), overwrite=True)\n",
    "        \n",
    "fout.close()\n",
    "model.save(os.path.join(DATA_DIR, \"rl-network.h5\"), overwrite=True)\n",
    "print(\"--- Tempo total: %d seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: data/rl-network.h5 (deflated 70%)\r\n"
     ]
    }
   ],
   "source": [
    "!zip data/nn.zip data/rl-network.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download: <a class=\"reference external\" href=\"data/nn.zip\" download=\"w3logo\">rl-network.h5</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
