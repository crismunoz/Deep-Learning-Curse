{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python game.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 1: Tesla C2070 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN not available)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dense, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.optimizers import Adam\n",
    "from scipy.misc import imresize\n",
    "import collections\n",
    "import numpy as np\n",
    "import os\n",
    "import wrapped_game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess_images(images):\n",
    "    if images.shape[0] < 4:\n",
    "        # single image\n",
    "        x_t = images[0]\n",
    "        x_t = imresize(x_t, (80, 80))\n",
    "        x_t = x_t.astype(\"float\")\n",
    "        x_t /= 255.0\n",
    "        s_t = np.stack((x_t, x_t, x_t, x_t), axis=2)\n",
    "    else:\n",
    "        # 4 images\n",
    "        xt_list = []\n",
    "        for i in range(images.shape[0]):\n",
    "            x_t = imresize(images[i], (80, 80))\n",
    "            x_t = x_t.astype(\"float\")\n",
    "            x_t /= 255.0\n",
    "            xt_list.append(x_t)\n",
    "        s_t = np.stack((xt_list[0], xt_list[1], xt_list[2], xt_list[3]), \n",
    "                       axis=2)\n",
    "    s_t = np.expand_dims(s_t, axis=0)\n",
    "    return s_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next_batch(experience, model, num_actions, gamma, batch_size):\n",
    "    batch_indices = np.random.randint(low=0, high=len(experience),\n",
    "                                      size=batch_size)\n",
    "    batch = random.sample(experience, batch_size)\n",
    "    X = np.zeros((batch_size, 80, 80, 4))\n",
    "    Y = np.zeros((batch_size, num_actions))\n",
    "    for i in range(len(batch)):\n",
    "        s_t, a_t, r_t, s_tp1, game_over = batch[i]\n",
    "        X[i] = s_t\n",
    "        Y[i] = model.predict(s_t)[0]\n",
    "        Q_sa = np.max(model.predict(s_tp1)[0])\n",
    "        if game_over:\n",
    "            Y[i, a_t] = r_t\n",
    "        else:\n",
    "            Y[i, a_t] = r_t + gamma * Q_sa\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "############################# main ###############################\n",
    "# initialize parameters\n",
    "DATA_DIR = \"data\"\n",
    "NUM_ACTIONS = 3 # number of valid actions (left, stay, right)\n",
    "GAMMA = 0.99 # decay rate of past observations\n",
    "INITIAL_EPSILON = 0.1 # starting value of epsilon\n",
    "FINAL_EPSILON = 0.0001 # final value of epsilon\n",
    "MEMORY_SIZE = 50000 # number of previous transitions to remember\n",
    "NUM_EPOCHS_OBSERVE = 100\n",
    "NUM_EPOCHS_TRAIN = 2000\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = NUM_EPOCHS_OBSERVE + NUM_EPOCHS_TRAIN\n",
    "\n",
    "# build the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=8, strides=4, \n",
    "                 kernel_initializer=\"normal\", \n",
    "                 padding=\"same\",\n",
    "                 input_shape=(80, 80, 4)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(64, kernel_size=4, strides=2, \n",
    "                 kernel_initializer=\"normal\", \n",
    "                 padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(64, kernel_size=3, strides=1,\n",
    "                 kernel_initializer=\"normal\",\n",
    "                 padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, kernel_initializer=\"normal\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(3, kernel_initializer=\"normal\"))\n",
    "\n",
    "model.compile(optimizer=Adam(lr=1e-6), loss=\"mse\")\n",
    "\n",
    "# train network\n",
    "game = wrapped_game.MyWrappedGame()\n",
    "experience = collections.deque(maxlen=MEMORY_SIZE)\n",
    "\n",
    "fout = open(os.path.join(DATA_DIR, \"rl-network-results.tsv\"), \"w\")\n",
    "num_games, num_wins = 0, 0\n",
    "epsilon = INITIAL_EPSILON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0001/2100 | Loss 0.00000 | Win Count: 0\n",
      "Epoch 0002/2100 | Loss 0.00000 | Win Count: 0\n",
      "Epoch 0003/2100 | Loss 0.00000 | Win Count: 0\n",
      "Epoch 0004/2100 | Loss 0.00000 | Win Count: 0\n",
      "Epoch 0005/2100 | Loss 0.00000 | Win Count: 0\n",
      "Epoch 0006/2100 | Loss 0.00000 | Win Count: 0\n",
      "Epoch 0007/2100 | Loss 0.00000 | Win Count: 0\n",
      "Epoch 0008/2100 | Loss 0.00000 | Win Count: 0\n",
      "Epoch 0009/2100 | Loss 0.00000 | Win Count: 0\n",
      "Epoch 0010/2100 | Loss 0.00000 | Win Count: 0\n",
      "Epoch 0011/2100 | Loss 0.00000 | Win Count: 0\n",
      "Epoch 0012/2100 | Loss 0.00000 | Win Count: 0\n",
      "Epoch 0013/2100 | Loss 0.00000 | Win Count: 0\n",
      "Epoch 0014/2100 | Loss 0.00000 | Win Count: 0\n",
      "Epoch 0015/2100 | Loss 0.00000 | Win Count: 0\n",
      "Epoch 0016/2100 | Loss 0.00000 | Win Count: 0\n",
      "Epoch 0017/2100 | Loss 0.00000 | Win Count: 1\n",
      "Epoch 0018/2100 | Loss 0.00000 | Win Count: 2\n",
      "Epoch 0019/2100 | Loss 0.00000 | Win Count: 3\n",
      "Epoch 0020/2100 | Loss 0.00000 | Win Count: 3\n",
      "Epoch 0021/2100 | Loss 0.00000 | Win Count: 3\n",
      "Epoch 0022/2100 | Loss 0.00000 | Win Count: 3\n",
      "Epoch 0023/2100 | Loss 0.00000 | Win Count: 3\n",
      "Epoch 0024/2100 | Loss 0.00000 | Win Count: 3\n",
      "Epoch 0025/2100 | Loss 0.00000 | Win Count: 3\n",
      "Epoch 0026/2100 | Loss 0.00000 | Win Count: 4\n",
      "Epoch 0027/2100 | Loss 0.00000 | Win Count: 4\n",
      "Epoch 0028/2100 | Loss 0.00000 | Win Count: 4\n",
      "Epoch 0029/2100 | Loss 0.00000 | Win Count: 4\n",
      "Epoch 0030/2100 | Loss 0.00000 | Win Count: 4\n",
      "Epoch 0031/2100 | Loss 0.00000 | Win Count: 4\n",
      "Epoch 0032/2100 | Loss 0.00000 | Win Count: 4\n",
      "Epoch 0033/2100 | Loss 0.00000 | Win Count: 4\n",
      "Epoch 0034/2100 | Loss 0.00000 | Win Count: 4\n",
      "Epoch 0035/2100 | Loss 0.00000 | Win Count: 4\n",
      "Epoch 0036/2100 | Loss 0.00000 | Win Count: 5\n",
      "Epoch 0037/2100 | Loss 0.00000 | Win Count: 5\n",
      "Epoch 0038/2100 | Loss 0.00000 | Win Count: 5\n",
      "Epoch 0039/2100 | Loss 0.00000 | Win Count: 5\n",
      "Epoch 0040/2100 | Loss 0.00000 | Win Count: 5\n",
      "Epoch 0041/2100 | Loss 0.00000 | Win Count: 5\n",
      "Epoch 0042/2100 | Loss 0.00000 | Win Count: 5\n",
      "Epoch 0043/2100 | Loss 0.00000 | Win Count: 5\n",
      "Epoch 0044/2100 | Loss 0.00000 | Win Count: 5\n",
      "Epoch 0045/2100 | Loss 0.00000 | Win Count: 5\n",
      "Epoch 0046/2100 | Loss 0.00000 | Win Count: 5\n",
      "Epoch 0047/2100 | Loss 0.00000 | Win Count: 5\n",
      "Epoch 0048/2100 | Loss 0.00000 | Win Count: 5\n",
      "Epoch 0049/2100 | Loss 0.00000 | Win Count: 5\n",
      "Epoch 0050/2100 | Loss 0.00000 | Win Count: 5\n",
      "Epoch 0051/2100 | Loss 0.00000 | Win Count: 5\n",
      "Epoch 0052/2100 | Loss 0.00000 | Win Count: 6\n",
      "Epoch 0053/2100 | Loss 0.00000 | Win Count: 6\n",
      "Epoch 0054/2100 | Loss 0.00000 | Win Count: 6\n",
      "Epoch 0055/2100 | Loss 0.00000 | Win Count: 6\n",
      "Epoch 0056/2100 | Loss 0.00000 | Win Count: 6\n",
      "Epoch 0057/2100 | Loss 0.00000 | Win Count: 7\n",
      "Epoch 0058/2100 | Loss 0.00000 | Win Count: 7\n",
      "Epoch 0059/2100 | Loss 0.00000 | Win Count: 7\n",
      "Epoch 0060/2100 | Loss 0.00000 | Win Count: 7\n",
      "Epoch 0061/2100 | Loss 0.00000 | Win Count: 7\n",
      "Epoch 0062/2100 | Loss 0.00000 | Win Count: 7\n",
      "Epoch 0063/2100 | Loss 0.00000 | Win Count: 7\n",
      "Epoch 0064/2100 | Loss 0.00000 | Win Count: 8\n",
      "Epoch 0065/2100 | Loss 0.00000 | Win Count: 8\n",
      "Epoch 0066/2100 | Loss 0.00000 | Win Count: 8\n",
      "Epoch 0067/2100 | Loss 0.00000 | Win Count: 8\n",
      "Epoch 0068/2100 | Loss 0.00000 | Win Count: 8\n",
      "Epoch 0069/2100 | Loss 0.00000 | Win Count: 8\n",
      "Epoch 0070/2100 | Loss 0.00000 | Win Count: 9\n",
      "Epoch 0071/2100 | Loss 0.00000 | Win Count: 9\n",
      "Epoch 0072/2100 | Loss 0.00000 | Win Count: 10\n",
      "Epoch 0073/2100 | Loss 0.00000 | Win Count: 10\n",
      "Epoch 0074/2100 | Loss 0.00000 | Win Count: 11\n",
      "Epoch 0075/2100 | Loss 0.00000 | Win Count: 11\n",
      "Epoch 0076/2100 | Loss 0.00000 | Win Count: 11\n",
      "Epoch 0077/2100 | Loss 0.00000 | Win Count: 11\n",
      "Epoch 0078/2100 | Loss 0.00000 | Win Count: 11\n",
      "Epoch 0079/2100 | Loss 0.00000 | Win Count: 11\n",
      "Epoch 0080/2100 | Loss 0.00000 | Win Count: 11\n",
      "Epoch 0081/2100 | Loss 0.00000 | Win Count: 11\n",
      "Epoch 0082/2100 | Loss 0.00000 | Win Count: 11\n",
      "Epoch 0083/2100 | Loss 0.00000 | Win Count: 11\n",
      "Epoch 0084/2100 | Loss 0.00000 | Win Count: 11\n",
      "Epoch 0085/2100 | Loss 0.00000 | Win Count: 12\n",
      "Epoch 0086/2100 | Loss 0.00000 | Win Count: 12\n",
      "Epoch 0087/2100 | Loss 0.00000 | Win Count: 12\n",
      "Epoch 0088/2100 | Loss 0.00000 | Win Count: 12\n",
      "Epoch 0089/2100 | Loss 0.00000 | Win Count: 12\n",
      "Epoch 0090/2100 | Loss 0.00000 | Win Count: 12\n",
      "Epoch 0091/2100 | Loss 0.00000 | Win Count: 12\n",
      "Epoch 0092/2100 | Loss 0.00000 | Win Count: 12\n",
      "Epoch 0093/2100 | Loss 0.00000 | Win Count: 12\n",
      "Epoch 0094/2100 | Loss 0.00000 | Win Count: 12\n",
      "Epoch 0095/2100 | Loss 0.00000 | Win Count: 12\n",
      "Epoch 0096/2100 | Loss 0.00000 | Win Count: 12\n",
      "Epoch 0097/2100 | Loss 0.00000 | Win Count: 12\n",
      "Epoch 0098/2100 | Loss 0.00000 | Win Count: 12\n",
      "Epoch 0099/2100 | Loss 0.00000 | Win Count: 12\n",
      "Epoch 0100/2100 | Loss 0.00000 | Win Count: 12\n",
      "Epoch 0101/2100 | Loss 0.00000 | Win Count: 12\n",
      "Epoch 0102/2100 | Loss 0.51459 | Win Count: 12\n",
      "Epoch 0103/2100 | Loss 0.51629 | Win Count: 12\n",
      "Epoch 0104/2100 | Loss 0.51989 | Win Count: 12\n",
      "Epoch 0105/2100 | Loss 0.38245 | Win Count: 12\n",
      "Epoch 0106/2100 | Loss 0.39269 | Win Count: 13\n",
      "Epoch 0107/2100 | Loss 0.36803 | Win Count: 13\n",
      "Epoch 0108/2100 | Loss 0.50551 | Win Count: 13\n",
      "Epoch 0109/2100 | Loss 0.33877 | Win Count: 13\n",
      "Epoch 0110/2100 | Loss 0.46822 | Win Count: 13\n",
      "Epoch 0111/2100 | Loss 0.39574 | Win Count: 13\n",
      "Epoch 0112/2100 | Loss 0.36780 | Win Count: 13\n",
      "Epoch 0113/2100 | Loss 0.38104 | Win Count: 13\n",
      "Epoch 0114/2100 | Loss 0.31408 | Win Count: 13\n",
      "Epoch 0115/2100 | Loss 0.45289 | Win Count: 14\n",
      "Epoch 0116/2100 | Loss 0.40075 | Win Count: 14\n",
      "Epoch 0117/2100 | Loss 0.30820 | Win Count: 14\n",
      "Epoch 0118/2100 | Loss 0.42456 | Win Count: 14\n",
      "Epoch 0119/2100 | Loss 0.41430 | Win Count: 14\n",
      "Epoch 0120/2100 | Loss 0.40609 | Win Count: 15\n",
      "Epoch 0121/2100 | Loss 0.32146 | Win Count: 15\n",
      "Epoch 0122/2100 | Loss 0.44762 | Win Count: 15\n",
      "Epoch 0123/2100 | Loss 0.37582 | Win Count: 15\n",
      "Epoch 0124/2100 | Loss 0.34811 | Win Count: 15\n",
      "Epoch 0125/2100 | Loss 0.38312 | Win Count: 15\n",
      "Epoch 0126/2100 | Loss 0.35050 | Win Count: 15\n",
      "Epoch 0127/2100 | Loss 0.38117 | Win Count: 15\n",
      "Epoch 0128/2100 | Loss 0.46987 | Win Count: 16\n",
      "Epoch 0129/2100 | Loss 0.44174 | Win Count: 16\n",
      "Epoch 0130/2100 | Loss 0.43792 | Win Count: 16\n",
      "Epoch 0131/2100 | Loss 0.29999 | Win Count: 16\n",
      "Epoch 0132/2100 | Loss 0.43650 | Win Count: 16\n",
      "Epoch 0133/2100 | Loss 0.46469 | Win Count: 17\n",
      "Epoch 0134/2100 | Loss 0.36177 | Win Count: 17\n",
      "Epoch 0135/2100 | Loss 0.41506 | Win Count: 18\n",
      "Epoch 0136/2100 | Loss 0.41474 | Win Count: 18\n",
      "Epoch 0137/2100 | Loss 0.45006 | Win Count: 18\n",
      "Epoch 0138/2100 | Loss 0.32059 | Win Count: 18\n",
      "Epoch 0139/2100 | Loss 0.42909 | Win Count: 18\n",
      "Epoch 0140/2100 | Loss 0.47870 | Win Count: 18\n",
      "Epoch 0141/2100 | Loss 0.53777 | Win Count: 18\n",
      "Epoch 0142/2100 | Loss 0.45175 | Win Count: 18\n",
      "Epoch 0143/2100 | Loss 0.45112 | Win Count: 18\n",
      "Epoch 0144/2100 | Loss 0.46925 | Win Count: 18\n",
      "Epoch 0145/2100 | Loss 0.38567 | Win Count: 19\n",
      "Epoch 0146/2100 | Loss 0.33435 | Win Count: 19\n",
      "Epoch 0147/2100 | Loss 0.48262 | Win Count: 19\n",
      "Epoch 0148/2100 | Loss 0.33057 | Win Count: 19\n",
      "Epoch 0149/2100 | Loss 0.44435 | Win Count: 19\n",
      "Epoch 0150/2100 | Loss 0.43446 | Win Count: 19\n",
      "Epoch 0151/2100 | Loss 0.31030 | Win Count: 19\n",
      "Epoch 0152/2100 | Loss 0.32966 | Win Count: 19\n",
      "Epoch 0153/2100 | Loss 0.33033 | Win Count: 19\n",
      "Epoch 0154/2100 | Loss 0.34348 | Win Count: 20\n",
      "Epoch 0155/2100 | Loss 0.34110 | Win Count: 20\n",
      "Epoch 0156/2100 | Loss 0.36722 | Win Count: 21\n",
      "Epoch 0157/2100 | Loss 0.46793 | Win Count: 21\n",
      "Epoch 0158/2100 | Loss 0.40730 | Win Count: 21\n",
      "Epoch 0159/2100 | Loss 0.41639 | Win Count: 21\n",
      "Epoch 0160/2100 | Loss 0.35125 | Win Count: 21\n",
      "Epoch 0161/2100 | Loss 0.37608 | Win Count: 21\n",
      "Epoch 0162/2100 | Loss 0.26810 | Win Count: 21\n",
      "Epoch 0163/2100 | Loss 0.42890 | Win Count: 21\n",
      "Epoch 0164/2100 | Loss 0.34808 | Win Count: 22\n",
      "Epoch 0165/2100 | Loss 0.38274 | Win Count: 22\n",
      "Epoch 0166/2100 | Loss 0.42151 | Win Count: 22\n",
      "Epoch 0167/2100 | Loss 0.44206 | Win Count: 22\n",
      "Epoch 0168/2100 | Loss 0.34976 | Win Count: 22\n",
      "Epoch 0169/2100 | Loss 0.43335 | Win Count: 22\n",
      "Epoch 0170/2100 | Loss 0.47163 | Win Count: 22\n",
      "Epoch 0171/2100 | Loss 0.36073 | Win Count: 22\n",
      "Epoch 0172/2100 | Loss 0.33635 | Win Count: 22\n",
      "Epoch 0173/2100 | Loss 0.35729 | Win Count: 22\n",
      "Epoch 0174/2100 | Loss 0.43174 | Win Count: 22\n",
      "Epoch 0175/2100 | Loss 0.39444 | Win Count: 22\n",
      "Epoch 0176/2100 | Loss 0.36507 | Win Count: 23\n",
      "Epoch 0177/2100 | Loss 0.38841 | Win Count: 23\n",
      "Epoch 0178/2100 | Loss 0.34397 | Win Count: 23\n",
      "Epoch 0179/2100 | Loss 0.31342 | Win Count: 23\n",
      "Epoch 0180/2100 | Loss 0.43207 | Win Count: 23\n",
      "Epoch 0181/2100 | Loss 0.33964 | Win Count: 23\n",
      "Epoch 0182/2100 | Loss 0.30446 | Win Count: 23\n",
      "Epoch 0183/2100 | Loss 0.31009 | Win Count: 24\n",
      "Epoch 0184/2100 | Loss 0.32541 | Win Count: 24\n",
      "Epoch 0185/2100 | Loss 0.33696 | Win Count: 24\n",
      "Epoch 0186/2100 | Loss 0.29346 | Win Count: 24\n",
      "Epoch 0187/2100 | Loss 0.42048 | Win Count: 24\n",
      "Epoch 0188/2100 | Loss 0.33446 | Win Count: 25\n",
      "Epoch 0189/2100 | Loss 0.35316 | Win Count: 25\n",
      "Epoch 0190/2100 | Loss 0.30705 | Win Count: 25\n",
      "Epoch 0191/2100 | Loss 0.29089 | Win Count: 25\n",
      "Epoch 0192/2100 | Loss 0.37140 | Win Count: 25\n",
      "Epoch 0193/2100 | Loss 0.37051 | Win Count: 25\n",
      "Epoch 0194/2100 | Loss 0.22777 | Win Count: 26\n",
      "Epoch 0195/2100 | Loss 0.35301 | Win Count: 26\n",
      "Epoch 0196/2100 | Loss 0.38515 | Win Count: 26\n",
      "Epoch 0197/2100 | Loss 0.18456 | Win Count: 26\n",
      "Epoch 0198/2100 | Loss 0.29031 | Win Count: 26\n",
      "Epoch 0199/2100 | Loss 0.24736 | Win Count: 26\n",
      "Epoch 0200/2100 | Loss 0.31886 | Win Count: 27\n",
      "Epoch 0201/2100 | Loss 0.26098 | Win Count: 27\n",
      "Epoch 0202/2100 | Loss 0.41899 | Win Count: 27\n",
      "Epoch 0203/2100 | Loss 0.37179 | Win Count: 27\n",
      "Epoch 0204/2100 | Loss 0.28785 | Win Count: 27\n",
      "Epoch 0205/2100 | Loss 0.31188 | Win Count: 27\n",
      "Epoch 0206/2100 | Loss 0.27609 | Win Count: 27\n",
      "Epoch 0207/2100 | Loss 0.31685 | Win Count: 27\n",
      "Epoch 0208/2100 | Loss 0.41068 | Win Count: 27\n",
      "Epoch 0209/2100 | Loss 0.23629 | Win Count: 27\n",
      "Epoch 0210/2100 | Loss 0.24714 | Win Count: 27\n",
      "Epoch 0211/2100 | Loss 0.29425 | Win Count: 27\n",
      "Epoch 0212/2100 | Loss 0.30431 | Win Count: 27\n",
      "Epoch 0213/2100 | Loss 0.24346 | Win Count: 27\n",
      "Epoch 0214/2100 | Loss 0.31514 | Win Count: 27\n",
      "Epoch 0215/2100 | Loss 0.35135 | Win Count: 27\n",
      "Epoch 0216/2100 | Loss 0.29152 | Win Count: 27\n",
      "Epoch 0217/2100 | Loss 0.34476 | Win Count: 27\n",
      "Epoch 0218/2100 | Loss 0.42023 | Win Count: 27\n",
      "Epoch 0219/2100 | Loss 0.33262 | Win Count: 28\n",
      "Epoch 0220/2100 | Loss 0.35971 | Win Count: 28\n",
      "Epoch 0221/2100 | Loss 0.30585 | Win Count: 28\n",
      "Epoch 0222/2100 | Loss 0.32641 | Win Count: 28\n",
      "Epoch 0223/2100 | Loss 0.24792 | Win Count: 28\n",
      "Epoch 0224/2100 | Loss 0.31368 | Win Count: 28\n",
      "Epoch 0225/2100 | Loss 0.32051 | Win Count: 28\n",
      "Epoch 0226/2100 | Loss 0.33090 | Win Count: 28\n",
      "Epoch 0227/2100 | Loss 0.38783 | Win Count: 28\n",
      "Epoch 0228/2100 | Loss 0.24220 | Win Count: 28\n",
      "Epoch 0229/2100 | Loss 0.18893 | Win Count: 29\n",
      "Epoch 0230/2100 | Loss 0.32646 | Win Count: 29\n",
      "Epoch 0231/2100 | Loss 0.23411 | Win Count: 29\n",
      "Epoch 0232/2100 | Loss 0.25116 | Win Count: 30\n",
      "Epoch 0233/2100 | Loss 0.32465 | Win Count: 31\n",
      "Epoch 0234/2100 | Loss 0.30994 | Win Count: 32\n",
      "Epoch 0235/2100 | Loss 0.18831 | Win Count: 32\n",
      "Epoch 0236/2100 | Loss 0.23996 | Win Count: 32\n",
      "Epoch 0237/2100 | Loss 0.33477 | Win Count: 32\n",
      "Epoch 0238/2100 | Loss 0.30916 | Win Count: 33\n",
      "Epoch 0239/2100 | Loss 0.23944 | Win Count: 33\n",
      "Epoch 0240/2100 | Loss 0.26553 | Win Count: 33\n",
      "Epoch 0241/2100 | Loss 0.18757 | Win Count: 33\n",
      "Epoch 0242/2100 | Loss 0.29093 | Win Count: 33\n",
      "Epoch 0243/2100 | Loss 0.25041 | Win Count: 33\n",
      "Epoch 0244/2100 | Loss 0.33369 | Win Count: 34\n",
      "Epoch 0245/2100 | Loss 0.22117 | Win Count: 34\n",
      "Epoch 0246/2100 | Loss 0.31245 | Win Count: 35\n",
      "Epoch 0247/2100 | Loss 0.26701 | Win Count: 36\n",
      "Epoch 0248/2100 | Loss 0.26062 | Win Count: 36\n",
      "Epoch 0249/2100 | Loss 0.21870 | Win Count: 37\n",
      "Epoch 0250/2100 | Loss 0.30144 | Win Count: 37\n",
      "Epoch 0251/2100 | Loss 0.32860 | Win Count: 37\n",
      "Epoch 0252/2100 | Loss 0.32219 | Win Count: 37\n",
      "Epoch 0253/2100 | Loss 0.31359 | Win Count: 37\n",
      "Epoch 0254/2100 | Loss 0.19682 | Win Count: 37\n",
      "Epoch 0255/2100 | Loss 0.29392 | Win Count: 37\n",
      "Epoch 0256/2100 | Loss 0.25034 | Win Count: 37\n",
      "Epoch 0257/2100 | Loss 0.27183 | Win Count: 37\n",
      "Epoch 0258/2100 | Loss 0.22716 | Win Count: 37\n",
      "Epoch 0259/2100 | Loss 0.24076 | Win Count: 38\n",
      "Epoch 0260/2100 | Loss 0.20772 | Win Count: 38\n",
      "Epoch 0261/2100 | Loss 0.19365 | Win Count: 38\n",
      "Epoch 0262/2100 | Loss 0.24697 | Win Count: 38\n",
      "Epoch 0263/2100 | Loss 0.24519 | Win Count: 39\n",
      "Epoch 0264/2100 | Loss 0.17357 | Win Count: 39\n",
      "Epoch 0265/2100 | Loss 0.22973 | Win Count: 39\n",
      "Epoch 0266/2100 | Loss 0.25438 | Win Count: 39\n",
      "Epoch 0267/2100 | Loss 0.28028 | Win Count: 39\n",
      "Epoch 0268/2100 | Loss 0.21852 | Win Count: 39\n",
      "Epoch 0269/2100 | Loss 0.17401 | Win Count: 40\n",
      "Epoch 0270/2100 | Loss 0.25414 | Win Count: 41\n",
      "Epoch 0271/2100 | Loss 0.18601 | Win Count: 41\n",
      "Epoch 0272/2100 | Loss 0.30201 | Win Count: 42\n",
      "Epoch 0273/2100 | Loss 0.28062 | Win Count: 43\n",
      "Epoch 0274/2100 | Loss 0.22414 | Win Count: 43\n",
      "Epoch 0275/2100 | Loss 0.28642 | Win Count: 43\n",
      "Epoch 0276/2100 | Loss 0.26758 | Win Count: 43\n",
      "Epoch 0277/2100 | Loss 0.24434 | Win Count: 43\n",
      "Epoch 0278/2100 | Loss 0.16947 | Win Count: 43\n",
      "Epoch 0279/2100 | Loss 0.15753 | Win Count: 43\n",
      "Epoch 0280/2100 | Loss 0.25892 | Win Count: 43\n",
      "Epoch 0281/2100 | Loss 0.18831 | Win Count: 43\n",
      "Epoch 0282/2100 | Loss 0.20899 | Win Count: 43\n",
      "Epoch 0283/2100 | Loss 0.17987 | Win Count: 43\n",
      "Epoch 0284/2100 | Loss 0.12995 | Win Count: 43\n",
      "Epoch 0285/2100 | Loss 0.22875 | Win Count: 43\n",
      "Epoch 0286/2100 | Loss 0.20311 | Win Count: 43\n",
      "Epoch 0287/2100 | Loss 0.34970 | Win Count: 43\n",
      "Epoch 0288/2100 | Loss 0.17982 | Win Count: 43\n",
      "Epoch 0289/2100 | Loss 0.17992 | Win Count: 43\n",
      "Epoch 0290/2100 | Loss 0.18968 | Win Count: 43\n",
      "Epoch 0291/2100 | Loss 0.17678 | Win Count: 44\n",
      "Epoch 0292/2100 | Loss 0.22811 | Win Count: 45\n",
      "Epoch 0293/2100 | Loss 0.24461 | Win Count: 46\n",
      "Epoch 0294/2100 | Loss 0.18207 | Win Count: 46\n",
      "Epoch 0295/2100 | Loss 0.18164 | Win Count: 47\n",
      "Epoch 0296/2100 | Loss 0.22634 | Win Count: 48\n",
      "Epoch 0297/2100 | Loss 0.21896 | Win Count: 48\n",
      "Epoch 0298/2100 | Loss 0.21017 | Win Count: 48\n",
      "Epoch 0299/2100 | Loss 0.21603 | Win Count: 49\n",
      "Epoch 0300/2100 | Loss 0.26546 | Win Count: 50\n",
      "Epoch 0301/2100 | Loss 0.24430 | Win Count: 50\n",
      "Epoch 0302/2100 | Loss 0.15794 | Win Count: 50\n",
      "Epoch 0303/2100 | Loss 0.21449 | Win Count: 50\n",
      "Epoch 0304/2100 | Loss 0.18059 | Win Count: 50\n",
      "Epoch 0305/2100 | Loss 0.20667 | Win Count: 50\n",
      "Epoch 0306/2100 | Loss 0.21960 | Win Count: 51\n",
      "Epoch 0307/2100 | Loss 0.21636 | Win Count: 51\n",
      "Epoch 0308/2100 | Loss 0.19985 | Win Count: 51\n",
      "Epoch 0309/2100 | Loss 0.22406 | Win Count: 52\n",
      "Epoch 0310/2100 | Loss 0.21030 | Win Count: 52\n",
      "Epoch 0311/2100 | Loss 0.17863 | Win Count: 52\n",
      "Epoch 0312/2100 | Loss 0.19416 | Win Count: 52\n",
      "Epoch 0313/2100 | Loss 0.23265 | Win Count: 52\n",
      "Epoch 0314/2100 | Loss 0.18077 | Win Count: 53\n",
      "Epoch 0315/2100 | Loss 0.23299 | Win Count: 53\n",
      "Epoch 0316/2100 | Loss 0.14982 | Win Count: 53\n",
      "Epoch 0317/2100 | Loss 0.18893 | Win Count: 53\n",
      "Epoch 0318/2100 | Loss 0.18725 | Win Count: 54\n",
      "Epoch 0319/2100 | Loss 0.24558 | Win Count: 54\n",
      "Epoch 0320/2100 | Loss 0.14950 | Win Count: 54\n",
      "Epoch 0321/2100 | Loss 0.15784 | Win Count: 55\n",
      "Epoch 0322/2100 | Loss 0.24609 | Win Count: 55\n",
      "Epoch 0323/2100 | Loss 0.17489 | Win Count: 56\n",
      "Epoch 0324/2100 | Loss 0.20353 | Win Count: 56\n",
      "Epoch 0325/2100 | Loss 0.13718 | Win Count: 57\n",
      "Epoch 0326/2100 | Loss 0.23857 | Win Count: 57\n",
      "Epoch 0327/2100 | Loss 0.18830 | Win Count: 57\n",
      "Epoch 0328/2100 | Loss 0.26242 | Win Count: 57\n",
      "Epoch 0329/2100 | Loss 0.22618 | Win Count: 58\n",
      "Epoch 0330/2100 | Loss 0.21406 | Win Count: 59\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c7dead4ca3ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# apply action, get reward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mx_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgame_over\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0ms_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;31m# if reward, increment num_wins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mr_t\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-cafba56afffd>\u001b[0m in \u001b[0;36mpreprocess_images\u001b[0;34m(images)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mxt_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mx_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mx_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"float\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mx_t\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/Tesla/miniconda3/envs/theano/lib/python3.5/site-packages/scipy/misc/pilutil.py\u001b[0m in \u001b[0;36mimresize\u001b[0;34m(arr, size, interp, mode)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'nearest'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lanczos'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bilinear'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bicubic'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cubic'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m     \u001b[0mimnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minterp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfromimage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/Tesla/miniconda3/envs/theano/lib/python3.5/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample)\u001b[0m\n\u001b[1;32m   1554\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGBa'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGBA'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1556\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1558\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNEAREST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for e in range(NUM_EPOCHS):\n",
    "    loss = 0.0\n",
    "    game.reset()\n",
    "    \n",
    "    # get first state\n",
    "    a_0 = 1  # (0 = left, 1 = stay, 2 = right)\n",
    "    x_t, r_0, game_over = game.step(a_0) \n",
    "    s_t = preprocess_images(x_t)\n",
    "\n",
    "    while not game_over:\n",
    "        s_tm1 = s_t\n",
    "        # next action\n",
    "        if e <= NUM_EPOCHS_OBSERVE:\n",
    "            a_t = np.random.randint(low=0, high=NUM_ACTIONS, size=1)[0]\n",
    "        else:\n",
    "            if np.random.rand() <= epsilon:\n",
    "                a_t = np.random.randint(low=0, high=NUM_ACTIONS, size=1)[0]\n",
    "            else:\n",
    "                q = model.predict(s_t)[0]\n",
    "                a_t = np.argmax(q)\n",
    "                \n",
    "        # apply action, get reward\n",
    "        x_t, r_t, game_over = game.step(a_t)\n",
    "        s_t = preprocess_images(x_t)\n",
    "        # if reward, increment num_wins\n",
    "        if r_t == 1:\n",
    "            num_wins += 1\n",
    "        # store experience\n",
    "        experience.append((s_tm1, a_t, r_t, s_t, game_over))\n",
    "        \n",
    "        if e > NUM_EPOCHS_OBSERVE:\n",
    "            # finished observing, now start training\n",
    "            # get next batch\n",
    "            X, Y = get_next_batch(experience, model, NUM_ACTIONS, \n",
    "                                  GAMMA, BATCH_SIZE)\n",
    "            loss += model.train_on_batch(X, Y)\n",
    "        \n",
    "    # reduce epsilon gradually\n",
    "    if epsilon > FINAL_EPSILON:\n",
    "        epsilon -= (INITIAL_EPSILON - FINAL_EPSILON) / NUM_EPOCHS\n",
    "        \n",
    "    print(\"Epoch {:04d}/{:d} | Loss {:.5f} | Win Count: {:d}\"\n",
    "          .format(e + 1, NUM_EPOCHS, loss, num_wins))\n",
    "    fout.write(\"{:04d}\\t{:.5f}\\t{:d}\\n\"\n",
    "          .format(e + 1, loss, num_wins))\n",
    "\n",
    "    if e % 100 == 0:\n",
    "        model.save(os.path.join(DATA_DIR, \"rl-network.h5\"), overwrite=True)\n",
    "        \n",
    "fout.close()\n",
    "model.save(os.path.join(DATA_DIR, \"rl-network.h5\"), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
