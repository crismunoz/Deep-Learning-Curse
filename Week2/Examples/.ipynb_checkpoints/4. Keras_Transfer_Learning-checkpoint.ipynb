{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Tensorflow - tf.contrib.learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste tutorial utilizaremos o framework **tf.contrib.learn**, que permite construir de forma fácil os modelos de Deep learning utilizando o API de alto nível [Estimator](https://www.tensorflow.org/api_guides/python/contrib.learn#estimators). Estimator oferece classes que você pode instanciar para configurar rapidamente tipos de modelos de classificadores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste exemplo vamos criar um rede Deep Learning para reconhecer digitos (Base de dados MNIST) e da um rótulo correto para cada imagem de dígito)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os dados do MNIST estão no site de [Yann LeCun](http://yann.lecun.com/exdb/mnist/). Os dados estão divididos em 3 partes:\n",
    "\n",
    "* **Treinamento**: 55,000 dados\n",
    "* **Teste**: 10,000 dados\n",
    "* **Validação**: 5,000 dados\n",
    "\n",
    "Os dados são imagens de 28x28 pixels de 1 canal, o seguinte código em python visualiza um elemento do dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from Lenet5_model import get_data_mnist\n",
    "\n",
    "train_data , train_labels , eval_data , eval_labels = get_data_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img=np.reshape(train_data[15],(28,28))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet-5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A estrutura da rede neural convolutiva (LeNet-5) proposta por [Yann lecun,1998](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf) é apresentada na Figura:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/lenet5.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O arquivo [Lenet5_model.py](../../edit/Examples/Lenet5_model.py) contém o código principal do modelo, vamos configurar uma versão similar da rede LeNet-5.\n",
    "\n",
    "Se pede contruir a siguente configuração de rede DL:\n",
    "\n",
    "* conv1: Camada convolutiva com 6 *features map* e um kernel de 5x5 por cada *features map*.\n",
    "* pool1: Camada max-pooling com 6 *features map* e um kernel de 2x2 e stride de 2 por cada *features map*.\n",
    "* conv2: Camada convolutiva com 16 *features map* e um kernel de 6x6 por cada *features map*.\n",
    "* pool2: Camada max-pooling com 16 *features map* e um kernel de 2x2 e stride de 2 por cada *features map*.\n",
    "* local3: Camada flat + Camada full-connected com 128 *features map*.\n",
    "* local4: Camada full-connected com 84 *features map*.\n",
    "* softmax: Camada softmax com 10 saídas (10 classes).\n",
    "\n",
    "Com mini-batch = **100** e steps = **2000**.\n",
    "\n",
    "Analisar os seguintes casos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!rm -rf train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caso 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizar o otimizador SGD ([Stochastic gradient descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent)) com taxa de aprendizagem 0.001 (optimizer='SGD')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cp Lenet5_model.py Lenet5_SGD_model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abrir o arquivo [Lenet5_SGD_model.py](../../edit/Lenet5_SGD_model.py) e completar o código para ter a seguinte distribuição de camadas solicitada (editar os **FIXME** no arquivo).\n",
    "\n",
    "Rodar o modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run Lenet5_SGD_model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caso 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copie o modelo já modificado Lenet5_SGD_model.py para Lenet5_RMS_model.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cp Lenet5_SGD_model.py Lenet5_RMS_model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No arquivo [Lenet5_RMS_model.py](../../edit/Lenet5_RMS_model.py), modificar o método de otimização para RMSProp:([Root Mean Square Propagation](http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf)) com taxa de aprendizagem 0.001 (optimizer=tf.train.RMSPropOptimizer(learning_rate=0.001))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Opcional 1**: Podemos observar alguns resultados no *tensorboard* para abrir executar na consola:\n",
    "\n",
    "tensorboard --logdir=train --port 8XXX\n",
    "\n",
    "**Opcional 2**: Adicionar variaveis para o *tensorboard*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para saber o IP de da maquina do servidor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!ifconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!tensorboard --logdir=train --port 8111"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modulos de keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.models import model_from_json\n",
    "from keras_tqdm import TQDMNotebookCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parametros da rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 5\n",
    "epochs = 5\n",
    "img_rows, img_cols = 28, 28\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leitura de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "now = datetime.datetime.now\n",
    "\n",
    "def train_model(model, train, test, num_classes):\n",
    "    x_train = train[0].reshape((train[0].shape[0],) + input_shape)\n",
    "    x_test = test[0].reshape((test[0].shape[0],) + input_shape)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    \n",
    "    \n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(train[1], num_classes)\n",
    "    y_test = keras.utils.to_categorical(test[1], num_classes)\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    t = now()\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=0,\n",
    "              callbacks=[TQDMNotebookCallback()],\n",
    "              validation_data=(x_test, y_test))\n",
    "    \n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    \n",
    "    print('Training time: %s' % (now() - t))\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# create two datasets one with digits below 5 and one with 5 and above\n",
    "x_train_lt5 = x_train[y_train < 5]\n",
    "y_train_lt5 = y_train[y_train < 5]\n",
    "x_test_lt5 = x_test[y_test < 5]\n",
    "y_test_lt5 = y_test[y_test < 5]\n",
    "\n",
    "x_train_gte5 = x_train[y_train >= 5]\n",
    "y_train_gte5 = y_train[y_train >= 5] - 5\n",
    "x_test_gte5 = x_test[y_test >= 5]\n",
    "y_test_gte5 = y_test[y_test >= 5] - 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criação do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_layers = [\n",
    "    Conv2D(36, kernel_size=(5, 5), activation='relu',input_shape=input_shape),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=2),\n",
    "    Conv2D(64, (6, 6), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=2),\n",
    "    Flatten()\n",
    "]\n",
    "\n",
    "classification_layers = [\n",
    "    Dense(1024, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "]\n",
    "\n",
    "model = Sequential(feature_layers + classification_layers)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create complete model\n",
    "model = Sequential(feature_layers + classification_layers)\n",
    "\n",
    "# train model for 5-digit classification [0..4]\n",
    "train_model(model,\n",
    "            (x_train_lt5, y_train_lt5),\n",
    "            (x_test_lt5, y_test_lt5), num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvamos o Modelo (.json e .h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# serializa modelo em formato JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serializa pesos pra HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Modelo armazenado no disco\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Em outro momento...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Modelo cargado do disco\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando as camadas de classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for l in feature_layers:\n",
    "    l.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_model(model,\n",
    "            (x_train_gte5, y_train_gte5),\n",
    "            (x_test_gte5, y_test_gte5), num_classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
