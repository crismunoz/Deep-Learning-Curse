{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create RNN Model\n",
    "\n",
    "\n",
    "![](img/gru_rnn_model.png)\n",
    "\n",
    "Considerando o batch_size ainda indeterminado (`None`)  a entrada na rede é um tensor de índices de palavras de dimensão `(None, MAX_SEQLEN, 1)`. Ele é processado através da camada **Embedding**, que converte cada palavra num vetor da forma `(EMBED_SIZE)`, pelo qual o tensor de saída desta camada tem a dimensão `(None, MAX_SEQLEN, EMBED_SIZE)`. O tensor é a entrada ao encoder GRU e sai com uma dimensão `HIDDEN_SIZE`. A camada GRU é configurada para retornar um único vetor de contexto (`return_sequences=False`) depois de observar uma seqüência de dimensão `MAX_SEQLEN`, então o tensor de saída da camada GRU tem a forma `(None, HIDDEN_SIZE)`. \n",
    "\n",
    "O vetor de contexto é logo replicado utilizando a camada `RepeatVector` em um tensor da forma `(None, MAX_SEQLEN, HIDDEN_SIZE)` e é a entrada ao decoder GRU. Logo passa por uma camada FC que produze um vetor de saída de dimensão `(None, MAX_SEQLEN,t_vocab_size)`. A função de ativação na camada FC é `softmax`. O argumento máximo `(argmax)` em cada coluna do tensor é indexada para prever o POS tag para a palavra em essa posição.\n",
    "\n",
    "A definição do modelo é feita por : `EMBED_SIZE, HIDDEN_SIZE, BATCH_SIZE` e `NUM_EPOCHS` são hiperparametros que tem sido atribuído com estes valores depois de experimentar com diferentes valores. O modelo é compilado com a função de perda `categorical_crossentropy` dado que temos multiplex categorias de rótulos, e o otimizador é utilizado o popular otimizador `adam`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "WARNING:theano.sandbox.cuda:The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla C2070 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN not available)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10947 249 3914 45 249 3914\n"
     ]
    }
   ],
   "source": [
    "%run '3.a. POS_tagging.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Activation, Dense, Dropout, RepeatVector, SpatialDropout1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "EMBED_SIZE = 128\n",
    "HIDDEN_SIZE = 64\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefa: Comparar GRU, LSTM e SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.recurrent import GRU\n",
    "np.random.seed(43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(s_vocabsize, EMBED_SIZE, input_length=MAX_SEQLEN, embeddings_initializer=\"glorot_uniform\"))\n",
    "#model.add(SpatialDropout1D(0.2))\n",
    "model.add(GRU(HIDDEN_SIZE, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(RepeatVector(MAX_SEQLEN))\n",
    "model.add(GRU(HIDDEN_SIZE, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(t_vocabsize)))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinamos este modelo para uma única época. O modelo tem muito parâmetros, e começa a ter overfit apos a primeira época de treinamento. Quando fornecemos a mesma data várias vezes ao longo das épocas, o modelo começa a ter um overfit nos dados de treinamento e piora os resultados com os dados de validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test score: 0.2929, accuracy 0.9109\n"
     ]
    }
   ],
   "source": [
    "model.fit(Xtrain, Ytrain, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS, validation_data=[Xtest, Ytest], \n",
    "          verbose=0, callbacks=[TQDMNotebookCallback()])\n",
    "score, acc = model.evaluate(Xtest, Ytest, batch_size=BATCH_SIZE, verbose=0)\n",
    "print(\"Test score: %.4f, accuracy %.4f\" % (score, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os models **Sequence-to-Sequence** são uma classe de modelos muito poderosos. Seu maior aplicação são maquinas de tradução, mais existe muitas outras aplicações como os exemplos anteriores. Muitas das tarefas de NLP, são maiores na hierarquia como:\n",
    "\n",
    "* **Named Entity Recognition** (para maior informação ler: [Named Entity Recofnition with Long Short Term Memory](http://delivery.acm.org/10.1145/1120000/1119202/p172-hammerton.pdf?ip=139.82.47.87&id=1119202&acc=OPEN&key=344E943C9DC262BB%2E5C4D48D3482FC7F0%2E4D4702B0C3E38B35%2E6D218144511F3437&CFID=767933077&CFTOKEN=20089988&__acm__=1495992801_1ee6b5e50f105ad8a61b0a59dd162da6), Hammerton, Proceeding of the Seventh Conference on Natural Language Learning, 2003).\n",
    "* **Sentence Parsing** (para maior informação ler os artigos: [Grammar as Foreing Language](https://arxiv.org/abs/1412.7449), O. Vinyals, Advances in Neural Information Processing Systems, 2015). \n",
    "* **Image captioning**: Também em redes de maior complexidade (para maior informação ler: [Deep Visual-Semantic Alignments for Generating Image Descriptions](https://cs.stanford.edu/people/karpathy/cvpr2015.pdf), A. Karpathy, e F. Li, Proceedings of the IEEE Conference on COmputer VIsion and Pattern Recognition, 2015)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidirectional RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em um determinado tempo *t*, a saida da RNN é dependente a todos os passos de tempo anteriores. Embora, é completamente possível que a saída seja também dependente de uma futura saída. Isto acontece especialmente em aplicações de NLP, onde talvez os atributos de uma palavra ou frases que tentamos predecir dependam do contexto dada pela frase completa, não só das palavras que precediam. RNNs bidirecionais também ajudam a arquitetura da rede dar igual importância ao início e final de a seqüência, e incrementa os dados disponíveis para treinamento.\n",
    "\n",
    "RNN bidirecionais são 2 RNN acoplados uma acima de outra, lendo a entrada no sentido oposto. Asim, em nosso exemplo, uma RNN vai ler as palavras de esquerda a direita e a outra RNN vai ler as palavras de direita a esquerda. A saída em cada intervalo de tempo sera baseado nos estados das camadas ocultas de ambas RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.layers.recurrent import LSTM\n",
    "np.random.seed(43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBED_SIZE = 128\n",
    "HIDDEN_SIZE = 64\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(s_vocabsize, EMBED_SIZE, input_length=MAX_SEQLEN, embeddings_initializer=\"glorot_uniform\"))\n",
    "#model.add(SpatialDropout1D(0.2))\n",
    "model.add(Bidirectional(LSTM(HIDDEN_SIZE, dropout=0.2, recurrent_dropout=0.2)))\n",
    "model.add(RepeatVector(MAX_SEQLEN))\n",
    "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
    "model.add(TimeDistributed(Dense(t_vocabsize)))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test score: 0.2797, accuracy 0.9116\n"
     ]
    }
   ],
   "source": [
    "model.fit(Xtrain, Ytrain, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS, validation_data=[Xtest, Ytest], \n",
    "          verbose=0, callbacks=[TQDMNotebookCallback()])\n",
    "score, acc = model.evaluate(Xtest, Ytest, batch_size=BATCH_SIZE, verbose=0)\n",
    "print(\"Test score: %.4f, accuracy %.4f\" % (score, acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "0a28f331fd2e45f18255d9e7e9483451": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "0e4e4d26bd9d41f8ab9c824574fb58cb": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "0edf515d65b641819fb3ce142697a889": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "58b09cd0336042d6a8cfe8257ec7039b": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "5f1b72bdd2d14ce18891b240c8b248c9": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "60cd0d727d134c228876654d8ac5601b": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "630c3a58409a4598aa03104f48dc1ce8": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "740c4ba0359845faae7d6c933c1300e6": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "84ef0516d7504600bbe26615522037c4": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "888ab393457d4618b183dc68645f0523": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "94bba571d3124995bd42b976ad641dd3": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "9ce15aa2901749878b14dac22240463f": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "a602a111e492426a988b512f61cb9505": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "b4ac5644cffd490b9e2cfa6dc959516d": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "bb6a91d2ee2440f3945372806d7488f3": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "c5ef67a0d4fe4a88b8b436ee6fdf6257": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "dd7b62722fb2444fbd2d93fde32ed530": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "e63cf8f7208846698dd876426e753a99": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "f5a9e6f45dbf4e1f94cd410f28c1a9be": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
